"""
åˆä½µæ›¸ç±ç›®éŒ„ - å°‡å…¬é–‹åœ–æ›¸é¤¨è³‡æ–™èˆ‡ç¾æœ‰ç›®éŒ„æ•´åˆ
"""

import json
from pathlib import Path
from datetime import datetime


def load_json(filepath: str):
    """è®€å– JSON æª”æ¡ˆ"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)


def save_json(data, filepath: str):
    """å„²å­˜ JSON æª”æ¡ˆ"""
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def merge_catalogs():
    """åˆä½µæ‰€æœ‰æ›¸ç±ç›®éŒ„"""
    base_dir = Path('/Users/kedewei/modernreader/data/catalogs')

    # è®€å–ç¾æœ‰ç›®éŒ„
    existing_books = []
    if (base_dir / 'sample_books.json').exists():
        existing_data = load_json(str(base_dir / 'sample_books.json'))
        # è™•ç†ä¸åŒæ ¼å¼
        if isinstance(existing_data, list):
            existing_books = existing_data
        elif isinstance(existing_data, dict):
            existing_books = existing_data.get('items', [])
        print(f"âœ“ è®€å–ç¾æœ‰ç›®éŒ„: {len(existing_books)} æœ¬æ›¸")

    # è®€å–å…¬é–‹åœ–æ›¸é¤¨è³‡æ–™
    public_books = []
    if (base_dir / 'public_library_books.json').exists():
        public_data = load_json(str(base_dir / 'public_library_books.json'))
        public_books = public_data.get('books', [])
        print(f"âœ“ è®€å–å…¬é–‹åœ–æ›¸é¤¨è³‡æ–™: {len(public_books)} æœ¬æ›¸")

    # åˆä½µï¼ˆé¿å…é‡è¤‡ï¼‰
    all_books = existing_books.copy()
    existing_ids = {book.get('id') for book in existing_books if 'id' in book}

    # ç‚ºèˆŠæ›¸ç±æ·»åŠ  IDï¼ˆå¦‚æœç¼ºå°‘ï¼‰
    for i, book in enumerate(all_books):
        if 'id' not in book:
            book['id'] = f"indigenous_{i+1:03d}"
            existing_ids.add(book['id'])

    for book in public_books:
        if book.get('id') not in existing_ids:
            all_books.append(book)

    print(f"âœ“ åˆä½µå¾Œç¸½è¨ˆ: {len(all_books)} æœ¬æ›¸")

    # å„²å­˜åˆä½µçµæœ
    merged_data = {
        'metadata': {
            'generated_at': datetime.now().isoformat(),
            'total_items': len(all_books),
            'description': 'åˆä½µåŸä½æ°‘èªæ›¸ç±èˆ‡å…¬é–‹åœ–æ›¸é¤¨é¤¨è—',
            'sources': [
                'åœ‹ç«‹å…¬å…±è³‡è¨Šåœ–æ›¸é¤¨ (NLPI)',
                'å—å°ç§‘æŠ€å¤§å­¸åœ–æ›¸é¤¨ (STUST)',
                'å°åŒ—å¸‚ç«‹åœ–æ›¸é¤¨ (TPML)',
                'é«˜é›„å¸‚ç«‹åœ–æ›¸é¤¨ (KSML)',
                'Indigenous Language Collection'
            ]
        },
        'items': all_books
    }

    # å‚™ä»½åŸå§‹æª”æ¡ˆ
    if (base_dir / 'sample_books.json').exists():
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = base_dir / f'sample_books.backup.{timestamp}.json'
        original = load_json(str(base_dir / 'sample_books.json'))
        save_json(original, str(backup_file))
        print(f"âœ“ å‚™ä»½åŸå§‹æª”æ¡ˆ: {backup_file.name}")

    # å„²å­˜åˆä½µçµæœ
    save_json(merged_data, str(base_dir / 'sample_books.json'))
    print(f"âœ“ å·²æ›´æ–°: {base_dir / 'sample_books.json'}")

    # çµ±è¨ˆè³‡è¨Š
    print("\n" + "="*60)
    print("ğŸ“Š ç›®éŒ„çµ±è¨ˆ")
    print("="*60)

    # æŒ‰ä¾†æºçµ±è¨ˆ
    sources = {}
    for book in all_books:
        metadata = book.get('metadata', {})
        source = metadata.get('source', book.get('source', 'Unknown'))
        sources[source] = sources.get(source, 0) + 1

    print("\nä¾†æºåˆ†ä½ˆ:")
    for source, count in sorted(sources.items(), key=lambda x: -x[1]):
        print(f"  â€¢ {source}: {count} æœ¬")

    # æŒ‰ä¸»é¡Œçµ±è¨ˆ
    topics = {}
    for book in all_books:
        for topic in book.get('topics', []):
            topics[topic] = topics.get(topic, 0) + 1

    print("\nç†±é–€ä¸»é¡Œ (å‰10):")
    for topic, count in sorted(topics.items(), key=lambda x: -x[1])[:10]:
        print(f"  â€¢ {topic}: {count} æœ¬")

    # æŒ‰èªè¨€çµ±è¨ˆ
    languages = {}
    for book in all_books:
        lang = book.get('language', 'unknown')
        languages[lang] = languages.get(lang, 0) + 1

    print("\nèªè¨€åˆ†ä½ˆ:")
    lang_names = {
        'zh': 'ä¸­æ–‡',
        'en': 'è‹±æ–‡',
        'ja': 'æ—¥æ–‡',
        'amis': 'é˜¿ç¾èª',
        'atayal': 'æ³°é›…èª',
        'paiwan': 'æ’ç£èª',
        'rukai': 'é­¯å‡±èª',
        'seediq': 'è³½å¾·å…‹èª',
        'tao': 'é”æ‚Ÿèª',
        'unknown': 'æœªçŸ¥'
    }
    for lang, count in sorted(languages.items(), key=lambda x: -x[1]):
        lang_name = lang_names.get(lang, lang)
        print(f"  â€¢ {lang_name}: {count} æœ¬")

    print("="*60)


if __name__ == '__main__':
    merge_catalogs()
