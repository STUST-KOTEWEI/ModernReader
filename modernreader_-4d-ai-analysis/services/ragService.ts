/**
 * RAG (Retrieval-Augmented Generation) Service
 * Enhanced AI generation with knowledge retrieval
 * Optimized for MacBook Air M3 8GB RAM
 */

import aiModelManager from './aiModelManager';
import { quantumKnowledgeBase } from './quantumKnowledgeBase';
import nlpService from './nlpService';

interface RAGConfig {
  retrievalCount: number; // æª¢ç´¢å¤šå°‘ç›¸é—œæ–‡æª”
  chunkSize: number; // æ–‡æœ¬åˆ†å¡Šå¤§å°
  chunkOverlap: number; // åˆ†å¡Šé‡ç–Š
  minRelevance: number; // æœ€å°ç›¸é—œåº¦é–¾å€¼
  useHybridSearch: boolean; // æ··åˆæœå°‹ï¼ˆé—œéµè©+èªç¾©ï¼‰
}

interface RAGResponse {
  answer: string;
  sources: Source[];
  confidence: number;
  processingTime: number;
  retrievedDocs: number;
}

interface Source {
  content: string;
  relevance: number;
  metadata?: any;
}

interface DocumentChunk {
  id: string;
  content: string;
  embedding?: number[];
  metadata: {
    documentId: string;
    chunkIndex: number;
    totalChunks: number;
  };
}

class RAGService {
  private config: RAGConfig = {
    retrievalCount: 5,
    chunkSize: 500,
    chunkOverlap: 50,
    minRelevance: 0.3,
    useHybridSearch: true,
  };

  private documentChunks: Map<string, DocumentChunk[]> = new Map();

  /**
   * æ·»åŠ æ–‡æª”åˆ° RAG ç³»çµ±
   */
  async addDocument(content: string, metadata?: any): Promise<string> {
    const documentId = this.generateId();
    
    // åˆ†å¡Šè™•ç†
    const chunks = this.chunkText(content);
    const documentChunks: DocumentChunk[] = [];

    console.log(`ğŸ“„ æ­£åœ¨è™•ç†æ–‡æª”: ${chunks.length} å€‹åˆ†å¡Š`);

    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      
      // æ·»åŠ åˆ°çŸ¥è­˜åº«
      const node = await quantumKnowledgeBase.addKnowledge(chunk, {
        type: 'concept',
        sources: [documentId],
        tags: metadata?.tags || [],
      });

      documentChunks.push({
        id: node.id,
        content: chunk,
        embedding: node.embeddings,
        metadata: {
          documentId,
          chunkIndex: i,
          totalChunks: chunks.length,
          ...metadata,
        },
      });
    }

    this.documentChunks.set(documentId, documentChunks);

    console.log(`âœ… æ–‡æª”å·²æ·»åŠ : ${documentId} (${chunks.length} å€‹åˆ†å¡Š)`);
    
    return documentId;
  }

  /**
   * RAG æŸ¥è©¢ï¼ˆæª¢ç´¢å¢å¼·ç”Ÿæˆï¼‰
   */
  async query(question: string, options?: Partial<RAGConfig>): Promise<RAGResponse> {
    const startTime = Date.now();
    const config = { ...this.config, ...options };

    console.log(`ğŸ” RAG æŸ¥è©¢: "${question}"`);

    // æ­¥é©Ÿ 1: æª¢ç´¢ç›¸é—œæ–‡æª”
    const retrievedDocs = await this.retrieve(question, config);

    if (retrievedDocs.length === 0) {
      console.warn('âš ï¸ æœªæ‰¾åˆ°ç›¸é—œæ–‡æª”');
      return {
        answer: 'æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è­˜åº«ä¸­æ²’æœ‰æ‰¾åˆ°ç›¸é—œä¿¡æ¯ä¾†å›ç­”é€™å€‹å•é¡Œã€‚',
        sources: [],
        confidence: 0,
        processingTime: Date.now() - startTime,
        retrievedDocs: 0,
      };
    }

    console.log(`ğŸ“š æª¢ç´¢åˆ° ${retrievedDocs.length} å€‹ç›¸é—œæ–‡æª”`);

    // æ­¥é©Ÿ 2: æ§‹å»ºå¢å¼·æç¤º
    const augmentedPrompt = this.buildAugmentedPrompt(question, retrievedDocs);

    // æ­¥é©Ÿ 3: ä½¿ç”¨ AI ç”Ÿæˆç­”æ¡ˆ
    const response = await aiModelManager.generate({
      prompt: augmentedPrompt,
      temperature: 0.3, // è¼ƒä½æº«åº¦ä»¥ç²å¾—æ›´æº–ç¢ºçš„ç­”æ¡ˆ
      maxTokens: 2048,
    });

    // æ­¥é©Ÿ 4: è¨ˆç®—ä¿¡å¿ƒåˆ†æ•¸
    const confidence = this.calculateConfidence(retrievedDocs, response.text);

    const processingTime = Date.now() - startTime;

    console.log(`âœ… RAG æŸ¥è©¢å®Œæˆ (${processingTime}ms, ä¿¡å¿ƒåº¦: ${(confidence * 100).toFixed(1)}%)`);

    return {
      answer: response.text.trim(),
      sources: retrievedDocs,
      confidence,
      processingTime,
      retrievedDocs: retrievedDocs.length,
    };
  }

  /**
   * å¤šè¼ªå°è©± RAG
   */
  async conversationalQuery(
    question: string,
    conversationHistory: Array<{ role: 'user' | 'assistant'; content: string }>,
    options?: Partial<RAGConfig>
  ): Promise<RAGResponse> {
    const config = { ...this.config, ...options };

    // å°‡å°è©±æ­·å²è½‰æ›ç‚ºä¸Šä¸‹æ–‡
    const conversationContext = conversationHistory
      .map(msg => `${msg.role === 'user' ? 'ç”¨æˆ¶' : 'AI'}: ${msg.content}`)
      .join('\n');

    // çµåˆå°è©±ä¸Šä¸‹æ–‡é€²è¡Œæª¢ç´¢
    const enhancedQuestion = `${conversationContext}\n\nç”¨æˆ¶: ${question}`;
    const retrievedDocs = await this.retrieve(enhancedQuestion, config);

    // æ§‹å»ºå°è©±å¢å¼·æç¤º
    const augmentedPrompt = `ä½ æ˜¯ä¸€å€‹çŸ¥è­˜åŠ©æ‰‹ã€‚æ ¹æ“šä»¥ä¸‹å°è©±æ­·å²å’Œç›¸é—œæ–‡æª”å›ç­”å•é¡Œã€‚

å°è©±æ­·å²ï¼š
${conversationContext}

ç›¸é—œæ–‡æª”ï¼š
${retrievedDocs.map((doc, i) => `[æ–‡æª” ${i + 1}]\n${doc.content}`).join('\n\n')}

ç”¨æˆ¶: ${question}

AI: `;

    const response = await aiModelManager.generate({
      prompt: augmentedPrompt,
      temperature: 0.4,
      maxTokens: 2048,
    });

    return {
      answer: response.text.trim(),
      sources: retrievedDocs,
      confidence: this.calculateConfidence(retrievedDocs, response.text),
      processingTime: 0,
      retrievedDocs: retrievedDocs.length,
    };
  }

  /**
   * æª¢ç´¢ç›¸é—œæ–‡æª”
   */
  private async retrieve(query: string, config: RAGConfig): Promise<Source[]> {
    // ä½¿ç”¨çŸ¥è­˜åº«çš„èªç¾©æœå°‹
    const results = await quantumKnowledgeBase.search(query, {
      limit: config.retrievalCount,
      minRelevance: config.minRelevance,
    });

    // è½‰æ›ç‚º Source æ ¼å¼
    const sources: Source[] = results.map(node => ({
      content: node.content,
      relevance: node.importance,
      metadata: {
        id: node.id,
        type: node.type,
        tags: node.tags,
        sources: node.sources,
      },
    }));

    // æŒ‰ç›¸é—œåº¦æ’åº
    sources.sort((a, b) => b.relevance - a.relevance);

    return sources;
  }

  /**
   * æ§‹å»ºå¢å¼·æç¤º
   */
  private buildAugmentedPrompt(question: string, sources: Source[]): string {
    const context = sources
      .map((source, index) => {
        return `[åƒè€ƒæ–‡ç» ${index + 1}] (ç›¸é—œåº¦: ${(source.relevance * 100).toFixed(0)}%)\n${source.content}`;
      })
      .join('\n\n');

    return `ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„çŸ¥è­˜åŠ©æ‰‹ã€‚è«‹æ ¹æ“šä»¥ä¸‹åƒè€ƒæ–‡ç»å›ç­”å•é¡Œã€‚

é‡è¦è¦å‰‡ï¼š
1. åªä½¿ç”¨æä¾›çš„åƒè€ƒæ–‡ç»ä¸­çš„ä¿¡æ¯
2. å¦‚æœåƒè€ƒæ–‡ç»ä¸­æ²’æœ‰è¶³å¤ ä¿¡æ¯ï¼Œæ˜ç¢ºèªªæ˜
3. å¼•ç”¨æ™‚è¨»æ˜åƒè€ƒæ–‡ç»ç·¨è™Ÿ
4. å›ç­”è¦æº–ç¢ºã€ç°¡æ½”ã€æœ‰æ¢ç†

åƒè€ƒæ–‡ç»ï¼š
${context}

å•é¡Œï¼š${question}

å›ç­”ï¼š`;
  }

  /**
   * è¨ˆç®—ä¿¡å¿ƒåˆ†æ•¸
   */
  private calculateConfidence(sources: Source[], answer: string): number {
    if (sources.length === 0) return 0;

    // åŸºæ–¼å¤šå€‹å› ç´ è¨ˆç®—ä¿¡å¿ƒåº¦
    const avgRelevance = sources.reduce((sum, s) => sum + s.relevance, 0) / sources.length;
    const sourceCount = Math.min(sources.length / this.config.retrievalCount, 1);
    const answerLength = Math.min(answer.length / 500, 1); // å‡è¨­ç†æƒ³ç­”æ¡ˆé•·åº¦ 500 å­—ç¬¦

    return (avgRelevance * 0.5 + sourceCount * 0.3 + answerLength * 0.2);
  }

  /**
   * æ–‡æœ¬åˆ†å¡Š
   */
  private chunkText(text: string): string[] {
    const { chunkSize, chunkOverlap } = this.config;
    const chunks: string[] = [];
    
    // æŒ‰å¥å­åˆ†å‰²
    const sentences = text.split(/[.!?ã€‚ï¼ï¼Ÿ\n]+/).filter(s => s.trim().length > 0);
    
    let currentChunk = '';
    let currentLength = 0;

    for (const sentence of sentences) {
      const sentenceLength = sentence.length;

      if (currentLength + sentenceLength > chunkSize && currentChunk.length > 0) {
        // ç•¶å‰åˆ†å¡Šå·²æ»¿ï¼Œä¿å­˜ä¸¦é–‹å§‹æ–°åˆ†å¡Š
        chunks.push(currentChunk.trim());
        
        // ä¿ç•™é‡ç–Šéƒ¨åˆ†
        const overlapText = currentChunk.slice(-chunkOverlap);
        currentChunk = overlapText + ' ' + sentence;
        currentLength = overlapText.length + sentenceLength;
      } else {
        currentChunk += (currentChunk ? ' ' : '') + sentence;
        currentLength += sentenceLength;
      }
    }

    if (currentChunk.trim().length > 0) {
      chunks.push(currentChunk.trim());
    }

    return chunks;
  }

  /**
   * æ‘˜è¦ç”Ÿæˆï¼ˆåŸºæ–¼æª¢ç´¢çš„æ‘˜è¦ï¼‰
   */
  async summarizeWithRAG(topic: string, maxLength: number = 300): Promise<string> {
    const sources = await this.retrieve(topic, {
      ...this.config,
      retrievalCount: 10,
    });

    if (sources.length === 0) {
      return `ç„¡æ³•æ‰¾åˆ°é—œæ–¼ã€Œ${topic}ã€çš„ç›¸é—œä¿¡æ¯ã€‚`;
    }

    const combinedText = sources.map(s => s.content).join('\n\n');

    const prompt = `è«‹æ ¹æ“šä»¥ä¸‹å…§å®¹ï¼Œç”Ÿæˆä¸€å€‹ç´„ ${maxLength} å­—çš„ç¶œåˆæ‘˜è¦ï¼Œä¸»é¡Œæ˜¯ã€Œ${topic}ã€ã€‚

å…§å®¹ï¼š
${combinedText}

æ‘˜è¦ï¼š`;

    const response = await aiModelManager.generate({
      prompt,
      temperature: 0.5,
      maxTokens: maxLength * 2,
    });

    return response.text.trim();
  }

  /**
   * äº‹å¯¦æ ¸æŸ¥
   */
  async factCheck(claim: string): Promise<{
    verdict: 'SUPPORTED' | 'REFUTED' | 'NOT_ENOUGH_INFO';
    confidence: number;
    evidence: Source[];
    explanation: string;
  }> {
    const sources = await this.retrieve(claim, {
      ...this.config,
      retrievalCount: 10,
    });

    const prompt = `è«‹æ ¹æ“šä»¥ä¸‹è­‰æ“šï¼Œåˆ¤æ–·é€™å€‹è²æ˜æ˜¯å¦æ­£ç¢ºã€‚

è²æ˜ï¼š${claim}

è­‰æ“šï¼š
${sources.map((s, i) => `[è­‰æ“š ${i + 1}] ${s.content}`).join('\n\n')}

è«‹ä»¥ JSON æ ¼å¼å›ç­”ï¼š
{
  "verdict": "SUPPORTED" | "REFUTED" | "NOT_ENOUGH_INFO",
  "confidence": 0.0-1.0,
  "explanation": "è©³ç´°è§£é‡‹"
}`;

    const response = await aiModelManager.generate({
      prompt,
      temperature: 0.2,
      maxTokens: 1024,
    });

    try {
      const result = JSON.parse(response.text.match(/\{[\s\S]*\}/)?.[0] || '{}');
      return {
        verdict: result.verdict || 'NOT_ENOUGH_INFO',
        confidence: result.confidence || 0,
        evidence: sources,
        explanation: result.explanation || 'ç„¡æ³•åˆ¤æ–·',
      };
    } catch (error) {
      console.error('äº‹å¯¦æ ¸æŸ¥è§£æå¤±æ•—:', error);
      return {
        verdict: 'NOT_ENOUGH_INFO',
        confidence: 0,
        evidence: sources,
        explanation: 'è§£æå¤±æ•—',
      };
    }
  }

  /**
   * å¼•ç”¨ç”Ÿæˆ
   */
  async generateCitation(question: string): Promise<{
    answer: string;
    citations: Array<{ text: string; source: string }>;
  }> {
    const ragResponse = await this.query(question);

    // ç”Ÿæˆå¸¶å¼•ç”¨çš„ç­”æ¡ˆ
    const citationsPrompt = `å°‡ä»¥ä¸‹ç­”æ¡ˆæ”¹å¯«ï¼Œæ·»åŠ é©ç•¶çš„å¼•ç”¨æ¨™è¨» [1], [2] ç­‰ã€‚

ç­”æ¡ˆï¼š
${ragResponse.answer}

åƒè€ƒæ–‡ç»ï¼š
${ragResponse.sources.map((s, i) => `[${i + 1}] ${s.content.substring(0, 100)}...`).join('\n')}

å¸¶å¼•ç”¨çš„ç­”æ¡ˆï¼š`;

    const response = await aiModelManager.generate({
      prompt: citationsPrompt,
      temperature: 0.3,
      maxTokens: 2048,
    });

    return {
      answer: response.text.trim(),
      citations: ragResponse.sources.map((s, i) => ({
        text: s.content,
        source: s.metadata?.sources?.[0] || `ä¾†æº ${i + 1}`,
      })),
    };
  }

  /**
   * æ‰¹æ¬¡æŸ¥è©¢
   */
  async batchQuery(questions: string[]): Promise<RAGResponse[]> {
    console.log(`ğŸš€ æ‰¹æ¬¡ RAG æŸ¥è©¢: ${questions.length} å€‹å•é¡Œ`);
    
    const results = await Promise.all(
      questions.map(q => this.query(q))
    );

    console.log('âœ… æ‰¹æ¬¡æŸ¥è©¢å®Œæˆ');
    return results;
  }

  /**
   * ç²å–æ–‡æª”çµ±è¨ˆ
   */
  getDocumentStats(): {
    totalDocuments: number;
    totalChunks: number;
    avgChunksPerDoc: number;
  } {
    const totalDocuments = this.documentChunks.size;
    let totalChunks = 0;

    this.documentChunks.forEach(chunks => {
      totalChunks += chunks.length;
    });

    return {
      totalDocuments,
      totalChunks,
      avgChunksPerDoc: totalDocuments > 0 ? totalChunks / totalDocuments : 0,
    };
  }

  /**
   * åˆªé™¤æ–‡æª”
   */
  async deleteDocument(documentId: string): Promise<void> {
    const chunks = this.documentChunks.get(documentId);
    if (!chunks) {
      console.warn(`æ–‡æª”ä¸å­˜åœ¨: ${documentId}`);
      return;
    }

    // å¾çŸ¥è­˜åº«ä¸­åˆªé™¤æ‰€æœ‰åˆ†å¡Š
    // (éœ€è¦å¯¦ä½œçŸ¥è­˜åº«çš„åˆªé™¤æ–¹æ³•)
    
    this.documentChunks.delete(documentId);
    console.log(`ğŸ—‘ï¸ æ–‡æª”å·²åˆªé™¤: ${documentId}`);
  }

  /**
   * æ›´æ–°é…ç½®
   */
  updateConfig(config: Partial<RAGConfig>): void {
    this.config = { ...this.config, ...config };
    console.log('âš™ï¸ RAG é…ç½®å·²æ›´æ–°:', this.config);
  }

  private generateId(): string {
    return `doc-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }
}

export const ragService = new RAGService();
export default ragService;
