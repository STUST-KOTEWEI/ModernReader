/**
 * Natural Language Processing Service
 * Advanced NLP capabilities using Gemini AI
 * Optimized for MacBook Air M3 8GB RAM
 */

import aiModelManager from './aiModelManager';

interface NLPAnalysis {
  entities: Entity[];
  keywords: Keyword[];
  sentiment: SentimentAnalysis;
  topics: Topic[];
  summary: string;
  language: string;
  complexity: ComplexityScore;
}

interface Entity {
  text: string;
  type: 'PERSON' | 'ORGANIZATION' | 'LOCATION' | 'DATE' | 'EVENT' | 'CONCEPT' | 'OTHER';
  salience: number; // 0-1
  mentions: number;
  context: string;
}

interface Keyword {
  text: string;
  score: number;
  frequency: number;
  tfidf: number;
}

interface SentimentAnalysis {
  score: number; // -1 to 1
  magnitude: number; // 0 to infinity
  label: 'POSITIVE' | 'NEGATIVE' | 'NEUTRAL' | 'MIXED';
  emotions: {
    joy: number;
    sadness: number;
    anger: number;
    fear: number;
    surprise: number;
  };
}

interface Topic {
  name: string;
  confidence: number;
  keywords: string[];
}

interface ComplexityScore {
  readingLevel: string;
  gradeLevel: number;
  avgSentenceLength: number;
  avgWordLength: number;
  syllablesPerWord: number;
}

class NLPService {
  private cache: Map<string, NLPAnalysis> = new Map();

  /**
   * å®Œæ•´ NLP åˆ†æ
   */
  async analyze(text: string): Promise<NLPAnalysis> {
    // æª¢æŸ¥å¿«å–
    const cacheKey = this.getCacheKey(text);
    if (this.cache.has(cacheKey)) {
      console.log('ğŸ“¦ ä½¿ç”¨å¿«å–çš„ NLP åˆ†æ');
      return this.cache.get(cacheKey)!;
    }

    console.log('ğŸ” é–‹å§‹ NLP åˆ†æ...');

    // ä¸¦è¡ŒåŸ·è¡Œå¤šå€‹åˆ†æä»»å‹™
    const [entities, keywords, sentiment, topics, summary, language, complexity] = await Promise.all([
      this.extractEntities(text),
      this.extractKeywords(text),
      this.analyzeSentiment(text),
      this.extractTopics(text),
      this.summarize(text, 100),
      this.detectLanguage(text),
      this.analyzeComplexity(text),
    ]);

    const analysis: NLPAnalysis = {
      entities,
      keywords,
      sentiment,
      topics,
      summary,
      language,
      complexity,
    };

    // å¿«å–çµæœ
    this.cache.set(cacheKey, analysis);
    
    // é™åˆ¶å¿«å–å¤§å°
    if (this.cache.size > 100) {
      const firstKey = this.cache.keys().next().value;
      this.cache.delete(firstKey);
    }

    console.log('âœ… NLP åˆ†æå®Œæˆ');
    return analysis;
  }

  /**
   * å¯¦é«”æŠ½å–ï¼ˆäººåã€åœ°åã€çµ„ç¹”ç­‰ï¼‰
   */
  async extractEntities(text: string): Promise<Entity[]> {
    const prompt = `åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œæå–æ‰€æœ‰é‡è¦å¯¦é«”ï¼ˆäººåã€åœ°åã€çµ„ç¹”ã€æ—¥æœŸã€äº‹ä»¶ã€æ¦‚å¿µç­‰ï¼‰ã€‚
å°æ¯å€‹å¯¦é«”æä¾›ï¼š
1. å¯¦é«”æ–‡æœ¬
2. é¡å‹ï¼ˆPERSON, ORGANIZATION, LOCATION, DATE, EVENT, CONCEPT, OTHERï¼‰
3. é‡è¦æ€§åˆ†æ•¸ (0-1)
4. å‡ºç¾æ¬¡æ•¸
5. ä¸Šä¸‹æ–‡

ä»¥ JSON æ ¼å¼è¿”å›çµæœã€‚

æ–‡æœ¬ï¼š
${text}

æ ¼å¼ï¼š
[{"text": "å¯¦é«”åç¨±", "type": "é¡å‹", "salience": 0.8, "mentions": 3, "context": "ä¸Šä¸‹æ–‡"}]`;

    const response = await aiModelManager.generate({
      prompt,
      temperature: 0.1, // ä½æº«åº¦ä»¥ç²å¾—ç²¾ç¢ºçµæœ
      maxTokens: 2048,
    });

    try {
      const entities = JSON.parse(this.extractJSON(response.text));
      return entities.slice(0, 20); // é™åˆ¶å‰ 20 å€‹æœ€é‡è¦çš„å¯¦é«”
    } catch (error) {
      console.error('å¯¦é«”æŠ½å–è§£æå¤±æ•—:', error);
      return [];
    }
  }

  /**
   * é—œéµè©æå–
   */
  async extractKeywords(text: string): Promise<Keyword[]> {
    const prompt = `æå–ä»¥ä¸‹æ–‡æœ¬çš„é—œéµè©ï¼ŒåŒ…æ‹¬ï¼š
1. é—œéµè©æ–‡æœ¬
2. é‡è¦æ€§åˆ†æ•¸ (0-1)
3. å‡ºç¾é »ç‡
4. TF-IDF åˆ†æ•¸

ä»¥ JSON æ ¼å¼è¿”å›å‰ 15 å€‹é—œéµè©ã€‚

æ–‡æœ¬ï¼š
${text}

æ ¼å¼ï¼š
[{"text": "é—œéµè©", "score": 0.9, "frequency": 5, "tfidf": 0.85}]`;

    const response = await aiModelManager.generate({
      prompt,
      temperature: 0.1,
      maxTokens: 1024,
    });

    try {
      const keywords = JSON.parse(this.extractJSON(response.text));
      return keywords;
    } catch (error) {
      console.error('é—œéµè©æå–è§£æå¤±æ•—:', error);
      return this.fallbackKeywordExtraction(text);
    }
  }

  /**
   * æƒ…æ„Ÿåˆ†æ
   */
  async analyzeSentiment(text: string): Promise<SentimentAnalysis> {
    const prompt = `åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå‚¾å‘ï¼š
1. æ•´é«”æƒ…æ„Ÿåˆ†æ•¸ (-1 åˆ° 1ï¼Œè² é¢åˆ°æ­£é¢)
2. æƒ…æ„Ÿå¼·åº¦ (0 åˆ° 1)
3. æƒ…æ„Ÿæ¨™ç±¤ (POSITIVE, NEGATIVE, NEUTRAL, MIXED)
4. è©³ç´°æƒ…ç·’åˆ†æ•¸ (joy, sadness, anger, fear, surpriseï¼Œå„ 0-1)

ä»¥ JSON æ ¼å¼è¿”å›çµæœã€‚

æ–‡æœ¬ï¼š
${text}

æ ¼å¼ï¼š
{
  "score": 0.5,
  "magnitude": 0.7,
  "label": "POSITIVE",
  "emotions": {"joy": 0.6, "sadness": 0.1, "anger": 0.0, "fear": 0.1, "surprise": 0.3}
}`;

    const response = await aiModelManager.generate({
      prompt,
      temperature: 0.2,
      maxTokens: 512,
    });

    try {
      return JSON.parse(this.extractJSON(response.text));
    } catch (error) {
      console.error('æƒ…æ„Ÿåˆ†æè§£æå¤±æ•—:', error);
      return {
        score: 0,
        magnitude: 0.5,
        label: 'NEUTRAL',
        emotions: { joy: 0.2, sadness: 0.2, anger: 0.2, fear: 0.2, surprise: 0.2 },
      };
    }
  }

  /**
   * ä¸»é¡Œæå–
   */
  async extractTopics(text: string): Promise<Topic[]> {
    const prompt = `è­˜åˆ¥ä»¥ä¸‹æ–‡æœ¬çš„ä¸»è¦ä¸»é¡Œã€‚å°æ¯å€‹ä¸»é¡Œæä¾›ï¼š
1. ä¸»é¡Œåç¨±
2. ä¿¡å¿ƒåˆ†æ•¸ (0-1)
3. ç›¸é—œé—œéµè©

ä»¥ JSON æ ¼å¼è¿”å›å‰ 5 å€‹ä¸»é¡Œã€‚

æ–‡æœ¬ï¼š
${text}

æ ¼å¼ï¼š
[{"name": "ä¸»é¡Œåç¨±", "confidence": 0.9, "keywords": ["é—œéµè©1", "é—œéµè©2"]}]`;

    const response = await aiModelManager.generate({
      prompt,
      temperature: 0.3,
      maxTokens: 1024,
    });

    try {
      return JSON.parse(this.extractJSON(response.text));
    } catch (error) {
      console.error('ä¸»é¡Œæå–è§£æå¤±æ•—:', error);
      return [];
    }
  }

  /**
   * æ–‡æœ¬æ‘˜è¦
   */
  async summarize(text: string, maxWords: number = 100): Promise<string> {
    const prompt = `è«‹å°‡ä»¥ä¸‹æ–‡æœ¬æ¿ƒç¸®ç‚ºç´„ ${maxWords} å­—çš„æ‘˜è¦ï¼Œä¿ç•™æ ¸å¿ƒè¦é»ã€‚

æ–‡æœ¬ï¼š
${text}

æ‘˜è¦ï¼š`;

    const response = await aiModelManager.generate({
      prompt,
      temperature: 0.5,
      maxTokens: maxWords * 3,
    });

    return response.text.trim();
  }

  /**
   * èªè¨€æª¢æ¸¬
   */
  detectLanguage(text: string): string {
    // ç°¡å–®çš„èªè¨€æª¢æ¸¬
    const chineseChars = (text.match(/[\u4e00-\u9fa5]/g) || []).length;
    const totalChars = text.length;
    
    if (chineseChars / totalChars > 0.3) {
      return 'zh-TW';
    } else if (/[ã-ã‚“ã‚¡-ãƒ¶ãƒ¼]/.test(text)) {
      return 'ja';
    } else if (/[ê°€-í£]/.test(text)) {
      return 'ko';
    } else {
      return 'en';
    }
  }

  /**
   * æ–‡æœ¬è¤‡é›œåº¦åˆ†æ
   */
  analyzeComplexity(text: string): ComplexityScore {
    const sentences = text.split(/[.!?ã€‚ï¼ï¼Ÿ]+/).filter(s => s.trim().length > 0);
    const words = text.split(/\s+/).filter(w => w.length > 0);
    
    const avgSentenceLength = words.length / sentences.length;
    const avgWordLength = text.length / words.length;
    
    // ä¼°è¨ˆéŸ³ç¯€æ•¸ï¼ˆç°¡åŒ–ç‰ˆï¼‰
    const syllablesPerWord = avgWordLength * 0.5;
    
    // Flesch-Kincaid Grade Level (ç°¡åŒ–ç‰ˆ)
    const gradeLevel = Math.max(0, Math.min(18,
      0.39 * avgSentenceLength + 11.8 * syllablesPerWord - 15.59
    ));

    let readingLevel: string;
    if (gradeLevel <= 6) readingLevel = 'Elementary';
    else if (gradeLevel <= 9) readingLevel = 'Middle School';
    else if (gradeLevel <= 12) readingLevel = 'High School';
    else readingLevel = 'College';

    return {
      readingLevel,
      gradeLevel: Math.round(gradeLevel * 10) / 10,
      avgSentenceLength: Math.round(avgSentenceLength * 10) / 10,
      avgWordLength: Math.round(avgWordLength * 10) / 10,
      syllablesPerWord: Math.round(syllablesPerWord * 10) / 10,
    };
  }

  /**
   * å•ç­”ç³»çµ±
   */
  async answerQuestion(context: string, question: string): Promise<string> {
    const prompt = `æ ¹æ“šä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”å•é¡Œã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²’æœ‰è¶³å¤ ä¿¡æ¯ï¼Œè«‹æ˜ç¢ºèªªæ˜ã€‚

ä¸Šä¸‹æ–‡ï¼š
${context}

å•é¡Œï¼š${question}

ç­”æ¡ˆï¼š`;

    const response = await aiModelManager.generate({
      prompt,
      temperature: 0.3,
      maxTokens: 512,
    });

    return response.text.trim();
  }

  /**
   * æ–‡æœ¬ç›¸ä¼¼åº¦è¨ˆç®—
   */
  async calculateSimilarity(text1: string, text2: string): Promise<number> {
    const prompt = `è©•ä¼°ä»¥ä¸‹å…©æ®µæ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼Œ0è¡¨ç¤ºå®Œå…¨ä¸åŒï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸åŒï¼‰ã€‚
åªè¿”å›ä¸€å€‹æ•¸å­—ã€‚

æ–‡æœ¬1ï¼š${text1.substring(0, 500)}
æ–‡æœ¬2ï¼š${text2.substring(0, 500)}

ç›¸ä¼¼åº¦ï¼š`;

    const response = await aiModelManager.generate({
      prompt,
      temperature: 0.1,
      maxTokens: 10,
    });

    const similarity = parseFloat(response.text.trim());
    return isNaN(similarity) ? 0 : Math.max(0, Math.min(1, similarity));
  }

  /**
   * æ–‡æœ¬åˆ†é¡
   */
  async classify(text: string, categories: string[]): Promise<{ category: string; confidence: number }[]> {
    const prompt = `å°‡ä»¥ä¸‹æ–‡æœ¬åˆ†é¡åˆ°é€™äº›é¡åˆ¥ä¹‹ä¸€ï¼š${categories.join(', ')}

ç‚ºæ¯å€‹é¡åˆ¥æä¾›ä¿¡å¿ƒåˆ†æ•¸ (0-1)ã€‚

æ–‡æœ¬ï¼š
${text}

ä»¥ JSON æ ¼å¼è¿”å›ï¼š
[{"category": "é¡åˆ¥å", "confidence": 0.8}]`;

    const response = await aiModelManager.generate({
      prompt,
      temperature: 0.2,
      maxTokens: 512,
    });

    try {
      const results = JSON.parse(this.extractJSON(response.text));
      return results.sort((a: any, b: any) => b.confidence - a.confidence);
    } catch (error) {
      console.error('åˆ†é¡è§£æå¤±æ•—:', error);
      return categories.map(cat => ({ category: cat, confidence: 1 / categories.length }));
    }
  }

  /**
   * å‘½åå¯¦é«”è­˜åˆ¥ï¼ˆNERï¼‰
   */
  async recognizeNamedEntities(text: string): Promise<Entity[]> {
    return this.extractEntities(text);
  }

  /**
   * é—œä¿‚æå–
   */
  async extractRelations(text: string): Promise<Array<{
    subject: string;
    predicate: string;
    object: string;
    confidence: number;
  }>> {
    const prompt = `æå–ä»¥ä¸‹æ–‡æœ¬ä¸­çš„é—œä¿‚ä¸‰å…ƒçµ„ï¼ˆä¸»èª-è¬‚èª-è³“èªï¼‰ã€‚

æ–‡æœ¬ï¼š
${text}

ä»¥ JSON æ ¼å¼è¿”å›ï¼š
[{"subject": "ä¸»èª", "predicate": "è¬‚èª", "object": "è³“èª", "confidence": 0.9}]`;

    const response = await aiModelManager.generate({
      prompt,
      temperature: 0.1,
      maxTokens: 2048,
    });

    try {
      return JSON.parse(this.extractJSON(response.text));
    } catch (error) {
      console.error('é—œä¿‚æå–è§£æå¤±æ•—:', error);
      return [];
    }
  }

  // ========== è¼”åŠ©æ–¹æ³• ==========

  private getCacheKey(text: string): string {
    // ä½¿ç”¨ç°¡å–®çš„å“ˆå¸Œå‡½æ•¸
    let hash = 0;
    for (let i = 0; i < text.length; i++) {
      const char = text.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash;
    }
    return hash.toString(36);
  }

  private extractJSON(text: string): string {
    // æå– JSON éƒ¨åˆ†ï¼ˆè™•ç†å¯èƒ½çš„ markdown æ ¼å¼ï¼‰
    const jsonMatch = text.match(/```(?:json)?\s*(\[[\s\S]*?\]|\{[\s\S]*?\})\s*```/);
    if (jsonMatch) {
      return jsonMatch[1];
    }
    
    // å˜—è©¦ç›´æ¥åŒ¹é… JSON
    const directMatch = text.match(/\[[\s\S]*?\]|\{[\s\S]*?\}/);
    if (directMatch) {
      return directMatch[0];
    }
    
    return text;
  }

  private fallbackKeywordExtraction(text: string): Keyword[] {
    // ç°¡å–®çš„é—œéµè©æå–å‚™ç”¨æ–¹æ¡ˆ
    const words = text.toLowerCase()
      .split(/\s+/)
      .filter(w => w.length > 3);

    const frequency = new Map<string, number>();
    words.forEach(word => {
      frequency.set(word, (frequency.get(word) || 0) + 1);
    });

    return Array.from(frequency.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(0, 15)
      .map(([text, freq]) => ({
        text,
        score: freq / words.length,
        frequency: freq,
        tfidf: freq / words.length,
      }));
  }

  /**
   * æ¸…é™¤å¿«å–
   */
  clearCache(): void {
    this.cache.clear();
    console.log('ğŸ—‘ï¸ NLP å¿«å–å·²æ¸…é™¤');
  }
}

export const nlpService = new NLPService();
export default nlpService;
